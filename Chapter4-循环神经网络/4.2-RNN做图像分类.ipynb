{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as tfs\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据\n",
    "data_tf = tfs.Compose([\n",
    "    tfs.ToTensor(),\n",
    "    tfs.Normalize([0.5], [0.5]) # 标准化\n",
    "])\n",
    "\n",
    "train_set = MNIST('./data', train=True, transform=data_tf, download=True)\n",
    "test_set = MNIST('./data', train=False, transform=data_tf, download=True)\n",
    "\n",
    "train_data = DataLoader(train_set, 64, True)\n",
    "test_data = DataLoader(test_set, 128, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, 1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, (ht, c) = self.lstm(x)\n",
    "        ht = ht.squeeze()\n",
    "        y_pred = self.fc(ht)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, 1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, ht = self.rnn(x)\n",
    "        ht = ht.squeeze()\n",
    "        y_pred = self.fc(ht)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = SimpleLSTM(28, 100)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(lstm.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1, train loss: 0.2080, train acc: 0.9389, test loss: 0.1797, test acc: 0.9418\n",
      "epoch:  2, train loss: 0.1307, train acc: 0.9599, test loss: 0.1020, test acc: 0.9699\n",
      "epoch:  3, train loss: 0.1007, train acc: 0.9695, test loss: 0.0937, test acc: 0.9731\n",
      "epoch:  4, train loss: 0.0830, train acc: 0.9755, test loss: 0.1038, test acc: 0.9700\n",
      "epoch:  5, train loss: 0.0681, train acc: 0.9794, test loss: 0.0920, test acc: 0.9744\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "Epochs = 5\n",
    "for epoch in range(Epochs):\n",
    "    loss_sum = 0\n",
    "    acc_sum = 0\n",
    "    for image, label in train_data:\n",
    "        image = Variable(image.squeeze())\n",
    "        label = Variable(label)\n",
    "        # 前向传播\n",
    "        y_pred = lstm(image)\n",
    "        loss = criterion(y_pred, label)\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_sum += loss.detach().item()\n",
    "        _, out = y_pred.max(1)                     # 返回每一行最大值对应的下标，就是图片的预测值\n",
    "        num_correct = (out == label).sum().item()  # 统计预测正确的数量\n",
    "        acc = num_correct / image.shape[0]         # 得到这一个batch的平均准确率\n",
    "        acc_sum += acc\n",
    "    ave_train_loss = loss_sum / len(train_data)\n",
    "    ave_train_acc = acc_sum / len(train_data)\n",
    "    loss_sum = 0\n",
    "    acc_sum = 0\n",
    "    # 在测试集上检验效果\n",
    "    lstm.eval()  # 将模型改为预测模式，eval（）时，pytorch会自动把BN和DropOut固定住，不会取平均，而是用训练好的值。\n",
    "    for image, label in test_data:\n",
    "        image = Variable(image.squeeze())\n",
    "        label = Variable(label)\n",
    "        y_pred = lstm(image)\n",
    "        loss = criterion(y_pred, label)\n",
    "        loss_sum += loss.detach().item()\n",
    "        _, out = y_pred.max(1)\n",
    "        num_correct = (out == label).sum().item()\n",
    "        acc = num_correct / image.shape[0]\n",
    "        acc_sum += acc\n",
    "    ave_test_loss = loss_sum / len(test_data)\n",
    "    ave_test_acc = acc_sum / len(test_data)\n",
    "    print('epoch: {:2d}, train loss: {:.4f}, train acc: {:.4f}, test loss: {:.4f}, test acc: {:.4f}'.format(epoch + 1, ave_train_loss, ave_train_acc, ave_test_loss, ave_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
