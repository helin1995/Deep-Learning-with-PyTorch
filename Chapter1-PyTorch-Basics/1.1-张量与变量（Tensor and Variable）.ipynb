{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关的库\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.70948982,  0.56337342, -0.05890747,  0.0325591 ,  1.8638594 ],\n",
       "       [-0.08806619,  1.00147051,  1.87643562, -0.5721189 , -0.40294095],\n",
       "       [-0.00733816,  0.12552496, -0.39004139, -0.28057637,  1.32415578],\n",
       "       [ 0.00690596,  0.08214539, -1.9701638 ,  0.20036706, -0.18938918]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个numpy数组\n",
    "numpy_array = np.random.randn(4, 5)  # 4-矩阵的行数，5-矩阵的列数，randn-正态分布\n",
    "numpy_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将numpy数组转换成PyTorch张量（Tensor）有如下两种方式：\n",
    "# 1、torch.Tensor(numpy_array)\n",
    "# 2、torch.from_numpy(numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7095,  0.5634, -0.0589,  0.0326,  1.8639],\n",
      "        [-0.0881,  1.0015,  1.8764, -0.5721, -0.4029],\n",
      "        [-0.0073,  0.1255, -0.3900, -0.2806,  1.3242],\n",
      "        [ 0.0069,  0.0821, -1.9702,  0.2004, -0.1894]])\n",
      "tensor([[-0.7095,  0.5634, -0.0589,  0.0326,  1.8639],\n",
      "        [-0.0881,  1.0015,  1.8764, -0.5721, -0.4029],\n",
      "        [-0.0073,  0.1255, -0.3900, -0.2806,  1.3242],\n",
      "        [ 0.0069,  0.0821, -1.9702,  0.2004, -0.1894]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "torch_tensor1 = torch.Tensor(numpy_array)\n",
    "torch_tensor2 = torch.from_numpy(numpy_array)\n",
    "print(torch_tensor1)\n",
    "print(torch_tensor2)\n",
    "# 使用以上两种方法进行转换的时候，会直接将numpy array的数据类型转换为对应的PyTorch Tensor类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 也可以使用以下方法将PyTorch Tensor转换为numpy array:\n",
    "# tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.7094898 ,  0.56337345, -0.05890747,  0.0325591 ,  1.8638594 ],\n",
       "       [-0.08806619,  1.0014706 ,  1.8764356 , -0.5721189 , -0.40294096],\n",
       "       [-0.00733816,  0.12552495, -0.39004138, -0.28057638,  1.3241558 ],\n",
       "       [ 0.00690596,  0.08214539, -1.9701638 ,  0.20036706, -0.18938917]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_array1 = torch_tensor1.numpy()\n",
    "numpy_array1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 访问Tensor的一些属性：大小、数据类型、维度和元素个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5])\n",
      "torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "# 1、大小\n",
    "print(torch_tensor1.shape)\n",
    "print(torch_tensor1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# 2、数据类型\n",
    "print(torch_tensor1.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# 3、维度\n",
    "print(torch_tensor1.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# 4、所有的元素个数\n",
    "print(torch_tensor1.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4728, -0.6310],\n",
      "        [ 0.2921,  1.4038],\n",
      "        [-0.1672,  1.0638]])\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# 练习：创建一个 float64、大小是 3 x 2、随机初始化的 tensor，将其转化为 numpy 的 ndarray，输出其数据类型\n",
    "x = torch.randn(3, 2)  # torch.randn(row, col) -> 生成一个row x col的随机张量，默认的数据类型是torch.FloatTensor\n",
    "print(x)\n",
    "x = x.type(torch.DoubleTensor)\n",
    "x = x.numpy()\n",
    "print(x.dtype)\n",
    "# tensor的数据类型与numpy array的数据类型的对应关系如下：\n",
    "# tensor数据类型      <-->     numpy array数据类型\n",
    "# torch.FloatTensor   <-->     float32\n",
    "# torch.DoubleTensor  <-->     float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor的一些操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2)\n",
    "print(x)\n",
    "# 使用torch内置的函数生成的tensor的数据类型都是torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "print(x.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "# 将其转换为整型\n",
    "x = x.type(torch.LongTensor)\n",
    "print(x)\n",
    "print(x.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5318,  0.8764, -0.3508],\n",
      "        [ 1.1702, -1.1039,  0.6730],\n",
      "        [-0.2964,  0.9932,  0.9772],\n",
      "        [ 1.3673, -0.9330,  0.3974]])\n"
     ]
    }
   ],
   "source": [
    "# 生成服从正态分布的随机矩阵（张量）\n",
    "x = torch.randn(4, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8764, 1.1702, 0.9932, 1.3673])\n"
     ]
    }
   ],
   "source": [
    "# 沿着行取最大值\n",
    "max_value, max_idx = torch.max(x, dim=1)  # 获得x每一行最大值组成的tensor以及最大值对应的下标组成的tensor\n",
    "print(max_value)\n",
    "# dim=1代表行，dim=0代表列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(max_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0062,  0.7393,  1.6739,  0.8317])\n"
     ]
    }
   ],
   "source": [
    "# 沿着行对x求和\n",
    "sum_x = torch.sum(x, dim=1)\n",
    "print(sum_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# 增加维度/减少维度\n",
    "print(x.size())\n",
    "x = x.unsqueeze(0)  # 在第一维增加，默认增加的维度值为1\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "x = x.unsqueeze(1)  # 在第二维增加\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "x = x.squeeze(0)  # 减少第一维\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 3])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "x = x.unsqueeze(0)\n",
    "print(x.size())\n",
    "x = x.squeeze()  # 如果不指定减少的维度，那么就将维度为1的全部去掉\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5228, -0.2066,  1.2517, -0.0956, -0.9913],\n",
      "         [ 0.5939, -0.3745,  0.6761, -0.7169,  0.0699],\n",
      "         [-0.1086, -0.2869,  1.4100,  0.9021,  1.4485],\n",
      "         [-0.6650, -1.2225, -1.4078,  0.4694,  0.0691]],\n",
      "\n",
      "        [[ 0.0381,  0.0493, -0.0357,  1.3380,  2.0331],\n",
      "         [ 0.9673,  0.5728, -1.5369,  0.3273, -0.0182],\n",
      "         [-0.5132, -0.1296,  0.9601,  0.6430,  0.3313],\n",
      "         [ 0.5773,  1.0815,  0.8792, -0.4347,  0.0882]],\n",
      "\n",
      "        [[ 0.4812, -0.8915,  1.3252, -0.9487, -0.3288],\n",
      "         [ 0.3955, -1.6038, -0.5757,  0.1552, -0.7201],\n",
      "         [ 0.6502,  0.5975,  1.2848, -0.3548,  0.4127],\n",
      "         [ 1.5145, -1.4020, -0.0115,  0.2202,  1.1712]]])\n",
      "torch.Size([3, 4, 5])\n",
      "tensor([[[-0.5228, -0.2066,  1.2517, -0.0956, -0.9913],\n",
      "         [ 0.0381,  0.0493, -0.0357,  1.3380,  2.0331],\n",
      "         [ 0.4812, -0.8915,  1.3252, -0.9487, -0.3288]],\n",
      "\n",
      "        [[ 0.5939, -0.3745,  0.6761, -0.7169,  0.0699],\n",
      "         [ 0.9673,  0.5728, -1.5369,  0.3273, -0.0182],\n",
      "         [ 0.3955, -1.6038, -0.5757,  0.1552, -0.7201]],\n",
      "\n",
      "        [[-0.1086, -0.2869,  1.4100,  0.9021,  1.4485],\n",
      "         [-0.5132, -0.1296,  0.9601,  0.6430,  0.3313],\n",
      "         [ 0.6502,  0.5975,  1.2848, -0.3548,  0.4127]],\n",
      "\n",
      "        [[-0.6650, -1.2225, -1.4078,  0.4694,  0.0691],\n",
      "         [ 0.5773,  1.0815,  0.8792, -0.4347,  0.0882],\n",
      "         [ 1.5145, -1.4020, -0.0115,  0.2202,  1.1712]]])\n",
      "torch.Size([4, 3, 5])\n",
      "tensor([[[-0.5228,  0.5939, -0.1086, -0.6650],\n",
      "         [ 0.0381,  0.9673, -0.5132,  0.5773],\n",
      "         [ 0.4812,  0.3955,  0.6502,  1.5145]],\n",
      "\n",
      "        [[-0.2066, -0.3745, -0.2869, -1.2225],\n",
      "         [ 0.0493,  0.5728, -0.1296,  1.0815],\n",
      "         [-0.8915, -1.6038,  0.5975, -1.4020]],\n",
      "\n",
      "        [[ 1.2517,  0.6761,  1.4100, -1.4078],\n",
      "         [-0.0357, -1.5369,  0.9601,  0.8792],\n",
      "         [ 1.3252, -0.5757,  1.2848, -0.0115]],\n",
      "\n",
      "        [[-0.0956, -0.7169,  0.9021,  0.4694],\n",
      "         [ 1.3380,  0.3273,  0.6430, -0.4347],\n",
      "         [-0.9487,  0.1552, -0.3548,  0.2202]],\n",
      "\n",
      "        [[-0.9913,  0.0699,  1.4485,  0.0691],\n",
      "         [ 2.0331, -0.0182,  0.3313,  0.0882],\n",
      "         [-0.3288, -0.7201,  0.4127,  1.1712]]])\n",
      "torch.Size([5, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 重新排列tensor的维度\n",
    "x = torch.randn(3, 4, 5)  # torch.randn(page, row, col)表示生成page个/页的row x col的矩阵\n",
    "print(x)\n",
    "print(x.size())\n",
    "\n",
    "# 1、permute可以重新排列tensor的维度\n",
    "x = x.permute(1, 0, 2)\n",
    "print(x)\n",
    "print(x.size())\n",
    "\n",
    "# 2、transpose可以交换tensor中的两个维度\n",
    "x = x.transpose(0, 2)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5659, -0.7582, -1.6545, -0.1380, -1.3386],\n",
      "         [-0.9407, -1.6829,  0.5473,  0.4574, -1.5802],\n",
      "         [-0.1080, -1.9968,  0.0184, -0.7080,  0.1897],\n",
      "         [-0.5889,  0.3203,  1.5985, -0.6179, -0.0100]],\n",
      "\n",
      "        [[ 0.2436,  0.5331, -1.1293, -2.9650, -1.3455],\n",
      "         [-0.4011, -0.1047,  0.0612, -0.8886,  0.3830],\n",
      "         [ 0.6025, -0.5958, -0.7919, -1.3748, -0.9960],\n",
      "         [-1.2596,  0.8188,  0.8267, -1.3869,  0.9227]],\n",
      "\n",
      "        [[ 1.0257, -1.5440, -1.3266, -1.2812,  2.9005],\n",
      "         [-0.4314, -1.6084, -1.5119, -0.5062,  1.0769],\n",
      "         [ 1.1831, -0.7531, -0.1329,  0.2261, -0.6193],\n",
      "         [ 0.4415, -0.1536,  0.1104, -0.0824,  1.1667]]])\n",
      "torch.Size([3, 4, 5])\n",
      "tensor([[-0.5659, -0.7582, -1.6545, -0.1380, -1.3386],\n",
      "        [-0.9407, -1.6829,  0.5473,  0.4574, -1.5802],\n",
      "        [-0.1080, -1.9968,  0.0184, -0.7080,  0.1897],\n",
      "        [-0.5889,  0.3203,  1.5985, -0.6179, -0.0100],\n",
      "        [ 0.2436,  0.5331, -1.1293, -2.9650, -1.3455],\n",
      "        [-0.4011, -0.1047,  0.0612, -0.8886,  0.3830],\n",
      "        [ 0.6025, -0.5958, -0.7919, -1.3748, -0.9960],\n",
      "        [-1.2596,  0.8188,  0.8267, -1.3869,  0.9227],\n",
      "        [ 1.0257, -1.5440, -1.3266, -1.2812,  2.9005],\n",
      "        [-0.4314, -1.6084, -1.5119, -0.5062,  1.0769],\n",
      "        [ 1.1831, -0.7531, -0.1329,  0.2261, -0.6193],\n",
      "        [ 0.4415, -0.1536,  0.1104, -0.0824,  1.1667]])\n",
      "torch.Size([12, 5])\n",
      "tensor([[-0.5659, -0.7582, -1.6545, -0.1380, -1.3386, -0.9407, -1.6829,  0.5473,\n",
      "          0.4574, -1.5802, -0.1080, -1.9968,  0.0184, -0.7080,  0.1897, -0.5889,\n",
      "          0.3203,  1.5985, -0.6179, -0.0100],\n",
      "        [ 0.2436,  0.5331, -1.1293, -2.9650, -1.3455, -0.4011, -0.1047,  0.0612,\n",
      "         -0.8886,  0.3830,  0.6025, -0.5958, -0.7919, -1.3748, -0.9960, -1.2596,\n",
      "          0.8188,  0.8267, -1.3869,  0.9227],\n",
      "        [ 1.0257, -1.5440, -1.3266, -1.2812,  2.9005, -0.4314, -1.6084, -1.5119,\n",
      "         -0.5062,  1.0769,  1.1831, -0.7531, -0.1329,  0.2261, -0.6193,  0.4415,\n",
      "         -0.1536,  0.1104, -0.0824,  1.1667]])\n",
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "# 使用view对tensor进行reshape\n",
    "x = torch.randn(3, 4, 5)\n",
    "print(x)\n",
    "print(x.size())\n",
    "\n",
    "x = x.view(-1, 5)  # -1表示任意维度，但是是确定的，因为可以由其他维度推断出来，比如在这个\n",
    "                   # 例子中，x总共有60个元素，现在其中一个维度等于5，那么另一个维度就等于12\n",
    "print(x)\n",
    "print(x.size())\n",
    "\n",
    "x = x.view(3, 20)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4799,  0.2519, -0.0413, -0.9004],\n",
      "        [ 1.5527,  1.4856,  0.6605, -3.1807],\n",
      "        [-2.0206, -3.2847,  1.1356,  0.4825]])\n",
      "tensor([[-1.4799,  0.2519, -0.0413, -0.9004],\n",
      "        [ 1.5527,  1.4856,  0.6605, -3.1807],\n",
      "        [-2.0206, -3.2847,  1.1356,  0.4825]])\n"
     ]
    }
   ],
   "source": [
    "# torch的加法与inplace操作\n",
    "# 1、加法\n",
    "x = torch.randn(3, 4)\n",
    "y = torch.randn(3, 4)\n",
    "\n",
    "z = x + y\n",
    "print(z)\n",
    "\n",
    "z = torch.add(x, y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4799,  0.2519, -0.0413, -0.9004],\n",
      "        [ 1.5527,  1.4856,  0.6605, -3.1807],\n",
      "        [-2.0206, -3.2847,  1.1356,  0.4825]])\n"
     ]
    }
   ],
   "source": [
    "# 2、inplace操作是直接对tensor进行操作而不需要另外开辟内存空间，一般是直接在操作符的后面加_\n",
    "x.add_(y)  # 相当于x = x + y\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 变量（Variable）\n",
    "## tensor 是 PyTorch 中的完美组件，但是构建神经网络还远远不够，我们需要能够构建计算图的 tensor，这就是 Variable。Variable 是对 tensor 的封装，操作和 tensor 是一样的，但是每个 Variabel都有三个属性:\n",
    "## 1、.data：变量的值，是一个tensor\n",
    "## 2、.grad：变量的梯度，是一个tensor\n",
    "## 3、.grad_fn：反映这个Variable是如何得到的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入Variable\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.randn(10, 5)\n",
    "y_tensor = torch.randn(10, 5)\n",
    "\n",
    "# 将tensor转换为Variable\n",
    "x = Variable(x_tensor, requires_grad=True)  # 默认Variable是不求梯度的，所以我们用这种方\n",
    "                                            # 式申明需要求梯度。\n",
    "y = Variable(y_tensor, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.sum(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-6.2925)\n",
      "<SumBackward0 object at 0x00000296EE6FFCC0>\n"
     ]
    }
   ],
   "source": [
    "print(z.data)\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 求x和y的梯度\n",
    "z.backward()\n",
    "\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 练习：\n",
    "### 尝试构建一个函数$y=x^2$，然后求$x=2$的导数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.FloatTensor([2]), requires_grad=True)\n",
    "y = x ** 2\n",
    "\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
